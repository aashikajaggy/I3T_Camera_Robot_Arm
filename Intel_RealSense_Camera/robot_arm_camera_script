
import pyrealsense2 as rs

import numpy as np

import cv2

import pandas as pd

import sys

from interbotix_common_modules.common_robot.robot import robot_shutdown, robot_startup
from interbotix_xs_modules.xs_robot.arm import InterbotixManipulatorXS



pipeline = rs.pipeline()


config = rs.config()


pipeline_wrapper = rs.pipeline_wrapper(pipeline)
pipeline_profile = config.resolve(pipeline_wrapper)
device = pipeline_profile.get_device()
device_product_line = str(device.get_info(rs.camera_info.product_line))

found_rgb = False
for s in device.sensors:
    if s.get_info(rs.camera_info.name) == 'RGB Camera':
        found_rgb = True
        break
if not found_rgb:
    print("The demo requires Depth camera with Color sensor")
    exit(0)


config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)



profile = pipeline.start(config)


depth_sensor = profile.get_device().first_depth_sensor()
depth_scale = depth_sensor.get_depth_scale()
print("Depth Scale is: " , depth_scale)



align_to = rs.stream.color
align = rs.align(align_to)

#depth_sensor = pipeline.get_active_profile().get_device().first_depth_sensor()
#depth_intrinsics = depth_sensor.get_stream_profiles()[0].as_video_stream_profile().get_intrinsics()


#this is intrinisc matrix for only the X and Y

def pixel_to_3d(u, v, depth_value, intrinsics):
    
    fx = intrinsics.fx #focal length in the x coordinate
    fy = intrinsics.fy #focal length in the y coordinate 
    ppx = intrinsics.ppx #principal point, where the optical axis intersects the image plane in the x axis
    ppy = intrinsics.ppy #principal point, where the optical axis intersects the image plane in the y axis 

    
    X = (u - ppx) * depth_value / fx #u=fx*x+cx, fy*y+cy
    Y = (v - ppy) * depth_value / fy
    Z = depth_value #z value represents the distance 

    return X, Y, Z


try:
    

    
    frames = pipeline.wait_for_frames()

    aligned_frames = align.process(frames)


    aligned_depth_frame = aligned_frames.get_depth_frame() 
    color_frame = aligned_frames.get_color_frame()

    color_stream_profile = color_frame.get_profile()
    color_intrinsics = color_stream_profile.as_video_stream_profile().get_intrinsics()

    unaligned_depth_frame = frames.get_depth_frame()



    depth_image = np.asanyarray(aligned_depth_frame.get_data())

    np.savetxt("depth_image_matrix.csv", depth_image)


    color_image = np.asanyarray(color_frame.get_data())

    cv2.imwrite("color_image_aligned.png", color_image)

    cv2.imwrite("depth_image_aligned.png", depth_image)
    gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)

    dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_7X7_50)
    parameters =  cv2.aruco.DetectorParameters()
    detector = cv2.aruco.ArucoDetector(dictionary, parameters)
    corners, ids, rejected = detector.detectMarkers(gray)

    

    print("corners", corners)

    corner_points = corners[0][0]

    avg_x=(corner_points[1][0]+corner_points[2][0])/2
    avg_x1=(corner_points[0][0]+corner_points[3][0])/2






    avg_y = (corner_points[0][1]+corner_points[1][1])/2
    avg_y1 = (corner_points[2][1]+corner_points[3][1])/2

 


    middle_x = (avg_x+avg_x1)/2
    middle_y = (avg_y+avg_y1)/2

    center_x = int(round(middle_x))
    center_y = int(round(middle_y))

    print("center_x")
    print(center_x)

    print("center_y")
    print(center_y)

    kernel_size = 50
    half_kernel = kernel_size // 2

    height, width = depth_image.shape
    print("depth image")
    print(depth_image[int(round(corner_points[0][1])),int(round(corner_points[1][1]))])
    kernel = np.zeros((kernel_size, kernel_size), dtype=np.uint16)

    for i in range(kernel_size):
        for j in range(kernel_size):
            x = center_x + (i - half_kernel)
            y = center_y + (j - half_kernel)
            if 0 <= x < width and 0 <= y < height:
                kernel[i, j] = depth_image[y, x]

    print("kernel")
    print(kernel)

    non_zero_indices = np.nonzero(kernel)

    # Extract non-zero values using the indices
    non_zero_values = kernel[non_zero_indices]
    print(non_zero_values.shape)
    average_depth = np.mean(non_zero_values[0])
    print("average_depth")
    print(average_depth)

    X, Y, Z = pixel_to_3d(center_x, center_y, average_depth, color_intrinsics)

    print("X")
    print(X)
    print("Y")
    print(Y)


    key = cv2.waitKey(1)

    bot = InterbotixManipulatorXS(
        robot_model='px100',
        group_name='arm',
        gripper_name='gripper',
    )

    robot_startup()
    bot.arm.go_to_home_pose()
    bot.arm.set_ee_cartesian_trajectory(x=-0.2)
    bot.arm.go_to_sleep_pose()
    robot_shutdown()

      
finally:
    pipeline.stop()